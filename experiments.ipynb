{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LM with retrieval\n",
    "\n",
    "Idea: verify that retrieval can improve prediction quality for small models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, FlaxBertForPreTraining, FlaxBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval model, dual encoder to retireve documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
      "INFO:absl:Unable to initialize backend 'gpu': NOT_FOUND: Could not find registered platform with name: \"cuda\". Available platform names are: Interpreter Host\n",
      "INFO:absl:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: {('pooler', 'dense', 'bias'), ('pooler', 'dense', 'kernel')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# A pretrained Hugging face model that is used for retrieval\n",
    "MODEL_TYPE = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n",
    "bert_encoder = FlaxBertModel.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try inference of the model\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"jax\")\n",
    "outputs = bert_encoder(**inputs)\n",
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.setup of DocumentEncoder(\n",
       "    # attributes\n",
       "    dimensions = [768, 768]\n",
       "    encoder = <transformers.models.bert.modeling_flax_bert.FlaxBertModel object at 0x7fb751b2dd30>\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DocumentEncoder(nn.Module):\n",
    "    dimensions: Sequence[int]\n",
    "    encoder: FlaxBertModel\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, input):\n",
    "        x = self.encoder(**inputs).pooler_output\n",
    "        for i, feat in enumerate(self.dimensions):\n",
    "            x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
    "            if i != len(self.dimensions) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x\n",
    "\n",
    "model = DocumentEncoder(dimensions=[768,768], encoder=bert_encoder)\n",
    "model.setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model parameters\n",
    "params = model.init(random.PRNGKey(0), inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-0.339502  ,  0.0432492 ,  0.01497814, -0.11061206,\n",
       "              -0.02616203, -0.02092332,  0.1959934 , -0.08281386,\n",
       "              -0.10037724,  0.06958833,  0.10271972,  0.33912143,\n",
       "              -0.16751938, -0.20066957, -0.12156841, -0.2113133 ,\n",
       "              -0.20840159, -0.04508257, -0.01584379,  0.21792877,\n",
       "               0.09600222,  0.39484373,  0.45374483,  0.34563887,\n",
       "               0.08924327, -0.12511891,  0.46351707,  0.05140289,\n",
       "              -0.33967775, -0.08923145,  0.00472189,  0.22341143,\n",
       "              -0.17614679,  0.07717368,  0.05756273,  0.20330286,\n",
       "              -0.03640734,  0.09931888,  0.01950785,  0.1644101 ,\n",
       "              -0.22386608,  0.02179904,  0.22025782, -0.02451881,\n",
       "              -0.23692493, -0.39110643, -0.16336784, -0.0746641 ,\n",
       "               0.54974484,  0.12904316,  0.08858219, -0.3262225 ,\n",
       "              -0.08783709, -0.09947664, -0.05356479,  0.2096961 ,\n",
       "              -0.3642194 , -0.13723595,  0.26316294,  0.15356146,\n",
       "              -0.06578732, -0.07990676,  0.05291862, -0.2562325 ,\n",
       "               0.10444679,  0.31863335, -0.12487391,  0.46370566,\n",
       "              -0.1617455 ,  0.2077466 ,  0.14755552,  0.23370826,\n",
       "              -0.12513775, -0.33238986,  0.00320069,  0.04141862,\n",
       "              -0.35357088,  0.11344073,  0.27558824, -0.2179535 ,\n",
       "               0.01060933, -0.3992239 ,  0.0912009 ,  0.25897336,\n",
       "               0.14556855, -0.34118563,  0.01428021,  0.27281684,\n",
       "               0.28951094, -0.04158369, -0.05346154, -0.2032815 ,\n",
       "              -0.00560501,  0.10269162, -0.09917572,  0.13954645,\n",
       "               0.25858393, -0.30993742,  0.32872966,  0.05068415,\n",
       "               0.00656337,  0.43067637,  0.0686789 ,  0.07532764,\n",
       "               0.0886456 , -0.09556055,  0.12496147, -0.09134295,\n",
       "              -0.42914724,  0.13035518, -0.22058351, -0.24851848,\n",
       "              -0.17101404,  0.20471415, -0.11246742,  0.23177432,\n",
       "              -0.05565599, -0.22983474,  0.01383274,  0.14803362,\n",
       "              -0.01721811, -0.27395475,  0.03531975,  0.4535229 ,\n",
       "               0.31054682, -0.07691005,  0.05189056, -0.02232459,\n",
       "               0.05661056, -0.00922995, -0.08247624,  0.08280682,\n",
       "              -0.2491055 , -0.09094293, -0.48750865, -0.11931297,\n",
       "               0.09398244,  0.18890387,  0.13830952, -0.19008043,\n",
       "              -0.1676154 ,  0.27353057, -0.33431453,  0.00229921,\n",
       "              -0.06714198,  0.03267352,  0.03452529, -0.09837942,\n",
       "              -0.16044919,  0.3553261 ,  0.03513431,  0.08386721,\n",
       "               0.20452955,  0.13926123, -0.22728021, -0.38418126,\n",
       "              -0.15362112,  0.13612314, -0.1734142 ,  0.13981353,\n",
       "               0.12949003,  0.16600876, -0.41995874,  0.18960147,\n",
       "               0.11639614, -0.13228299,  0.3683162 , -0.2972594 ,\n",
       "              -0.28669053, -0.20129254, -0.11460215, -0.15458027,\n",
       "               0.03872923, -0.19072135, -0.12243551,  0.15964448,\n",
       "              -0.31721362,  0.49159163, -0.23327993, -0.2887986 ,\n",
       "              -0.25116104,  0.12202302, -0.13245703, -0.03583846,\n",
       "              -0.06662992, -0.11503891, -0.17567283,  0.18142004,\n",
       "              -0.19618738, -0.22798648,  0.07177097, -0.12285689,\n",
       "              -0.10987832, -0.33629313, -0.06275294, -0.05090464,\n",
       "               0.44954687,  0.12468782,  0.24559581,  0.4307724 ,\n",
       "              -0.31743088,  0.21202907, -0.30194253,  0.20664106,\n",
       "               0.6060862 , -0.33129644,  0.24856468, -0.11830499,\n",
       "              -0.43981332,  0.05260923,  0.29402894, -0.02422324,\n",
       "              -0.3514377 ,  0.03146641, -0.34788606,  0.45076525,\n",
       "              -0.10538755,  0.18707645, -0.16288644, -0.04482402,\n",
       "              -0.28189752,  0.00798119, -0.1413748 , -0.15019052,\n",
       "               0.42014524, -0.0908611 , -0.0015988 ,  0.20906863,\n",
       "               0.4671185 , -0.14921923, -0.03692202, -0.3083049 ,\n",
       "               0.13072371, -0.07684413, -0.05552778,  0.33751425,\n",
       "               0.16796346, -0.10265297, -0.00256018, -0.13903481,\n",
       "               0.25891444,  0.14135113,  0.36150494,  0.1788419 ,\n",
       "              -0.35886565,  0.14714769,  0.09464607, -0.12004011,\n",
       "              -0.0438971 , -0.42928803,  0.02020344,  0.19533034,\n",
       "              -0.24702771, -0.2673334 ,  0.04949867, -0.28125066,\n",
       "               0.30496246, -0.07848012, -0.16623157, -0.18158154,\n",
       "              -0.09239143,  0.16919345, -0.438073  ,  0.10497772,\n",
       "              -0.2360735 , -0.09528232,  0.04761368,  0.11788712,\n",
       "               0.15194651, -0.32177207,  0.2431686 ,  0.01496277,\n",
       "              -0.0932095 ,  0.05145917, -0.09049711, -0.04329429,\n",
       "              -0.01648581, -0.01560382, -0.25715667,  0.11691395,\n",
       "              -0.06701396,  0.02658505,  0.14509432,  0.03696944,\n",
       "               0.16978987, -0.05345232, -0.08963216, -0.00784278,\n",
       "               0.06609481, -0.14505152,  0.12804589, -0.15495898,\n",
       "               0.20185164, -0.04201351, -0.3331763 , -0.22677262,\n",
       "              -0.49518132, -0.05388211,  0.2795136 , -0.10840144,\n",
       "              -0.06890349,  0.27437714,  0.27013102, -0.2574904 ,\n",
       "              -0.10188358,  0.0247374 , -0.21566881,  0.26934242,\n",
       "               0.20420459, -0.22336107, -0.04637682,  0.46784627,\n",
       "              -0.04117543,  0.21789326,  0.39225888, -0.03683804,\n",
       "              -0.06217212,  0.21069734, -0.02456454, -0.22731073,\n",
       "              -0.47572792, -0.00879439, -0.20891511, -0.10227215,\n",
       "              -0.02595685,  0.62538344, -0.05978953,  0.13153549,\n",
       "              -0.04030574,  0.229726  , -0.11314488,  0.03243184,\n",
       "               0.4297026 ,  0.13276137,  0.11886517,  0.3457585 ,\n",
       "               0.26692218,  0.16087213, -0.02814336,  0.02163742,\n",
       "              -0.2561297 ,  0.22422002,  0.11587393,  0.2024119 ,\n",
       "               0.38187644, -0.2221719 , -0.00689461, -0.19473289,\n",
       "              -0.00667372, -0.09971429, -0.27955952,  0.10337295,\n",
       "               0.6232422 ,  0.21951762,  0.13420807,  0.06950875,\n",
       "               0.13049659,  0.22274406, -0.1733371 ,  0.40865475,\n",
       "               0.01256139,  0.23048119,  0.09920309, -0.18443559,\n",
       "               0.14744575,  0.02717527, -0.09357636, -0.20167743,\n",
       "              -0.09991373, -0.09802345, -0.2995992 , -0.16284555,\n",
       "              -0.02664243,  0.1686599 , -0.09959166,  0.05196398,\n",
       "               0.16472226, -0.12095207, -0.17663358, -0.00220434,\n",
       "               0.19769748, -0.09054742, -0.0900401 , -0.24346156,\n",
       "              -0.01646368,  0.119538  ,  0.20578568,  0.24667415,\n",
       "              -0.24656814,  0.1532376 ,  0.16263035,  0.17504881,\n",
       "              -0.23880453, -0.15533538, -0.07129371, -0.18576087,\n",
       "              -0.23059326,  0.33411863,  0.03037845, -0.04135746,\n",
       "              -0.0257126 , -0.34598702,  0.3545187 , -0.13474359,\n",
       "              -0.21676008, -0.14821532, -0.18310994, -0.28836557,\n",
       "              -0.50840765, -0.20034914,  0.040251  ,  0.22025678,\n",
       "              -0.534068  ,  0.03706793, -0.39259067, -0.07274756,\n",
       "              -0.36219642, -0.32538188, -0.07278089,  0.01578395,\n",
       "              -0.07623526, -0.3831185 , -0.38712066,  0.01681196,\n",
       "              -0.0387103 ,  0.39774567, -0.4820895 ,  0.16820481,\n",
       "              -0.18709499,  0.18607663, -0.11903399, -0.2373997 ,\n",
       "               0.38247126,  0.12460936,  0.2153225 , -0.04484778,\n",
       "               0.08573852,  0.26257238, -0.40624157,  0.13265532,\n",
       "              -0.02440103, -0.177156  , -0.11766049, -0.12418516,\n",
       "               0.04199731, -0.07110862,  0.13336478, -0.5823533 ,\n",
       "               0.0785955 , -0.07233041, -0.09656867, -0.5326627 ,\n",
       "              -0.2549198 , -0.17875962, -0.2630507 , -0.06131667,\n",
       "              -0.00785888,  0.03289053,  0.15133211, -0.00671336,\n",
       "              -0.2292106 , -0.0685326 ,  0.15096389,  0.10477291,\n",
       "               0.02819513, -0.04215428, -0.09183618,  0.07356695,\n",
       "              -0.14617431,  0.31971893, -0.08699962,  0.21972078,\n",
       "              -0.07238384,  0.05632824,  0.07605715,  0.17193033,\n",
       "              -0.00065446,  0.16352771, -0.06425749, -0.08290809,\n",
       "              -0.0799979 ,  0.13538866,  0.50538033,  0.14050959,\n",
       "               0.07249273, -0.16621242,  0.07290912,  0.07947622,\n",
       "               0.1123908 , -0.00483588, -0.32601428, -0.04930899,\n",
       "               0.1492144 , -0.22199436, -0.09760141, -0.31387672,\n",
       "              -0.10687983, -0.1807083 ,  0.02506782,  0.10637349,\n",
       "              -0.46485043, -0.19745715,  0.23742336, -0.09944817,\n",
       "              -0.10900634,  0.30602723,  0.12123308, -0.11160805,\n",
       "              -0.150117  ,  0.07164462,  0.42712057,  0.10011958,\n",
       "               0.15691143,  0.16331168,  0.10851808,  0.52137434,\n",
       "              -0.08568972, -0.1880731 ,  0.23676875,  0.07599691,\n",
       "               0.06138267, -0.06053373,  0.26090214,  0.07381258,\n",
       "              -0.12839542,  0.07739172, -0.39657786,  0.3919349 ,\n",
       "              -0.00231336,  0.10985836, -0.2548973 ,  0.15320054,\n",
       "               0.17835157, -0.47593403, -0.01156847,  0.07492177,\n",
       "              -0.20580462, -0.16541058,  0.20042665, -0.0414133 ,\n",
       "              -0.04184747, -0.16679573, -0.08243178, -0.09671776,\n",
       "              -0.22435336,  0.29285017, -0.06792159,  0.2583624 ,\n",
       "               0.01399976, -0.24765274, -0.09712462, -0.01002231,\n",
       "              -0.3318458 , -0.11538947, -0.08736158,  0.17435151,\n",
       "              -0.19471739, -0.04833259,  0.24272674,  0.11301917,\n",
       "               0.13767251, -0.44452393,  0.2219051 , -0.14177397,\n",
       "               0.00394281,  0.3433495 , -0.12393907, -0.2241707 ,\n",
       "              -0.03195243,  0.02386275,  0.1279838 ,  0.11270486,\n",
       "               0.05975788, -0.13299422,  0.14324419,  0.3216124 ,\n",
       "               0.24569058, -0.05160099,  0.18186119, -0.15102434,\n",
       "               0.03531656, -0.25096673,  0.00235518,  0.16202535,\n",
       "              -0.2865752 ,  0.36654142, -0.04848678,  0.30713522,\n",
       "               0.04244658, -0.27768996,  0.01543017, -0.2989097 ,\n",
       "               0.17452116,  0.01270838, -0.16249764,  0.13875571,\n",
       "               0.01719594, -0.0945788 , -0.09770937,  0.43359542,\n",
       "              -0.2723111 ,  0.20889972,  0.0340256 ,  0.17113045,\n",
       "              -0.32461768, -0.03190777,  0.09858453, -0.1847364 ,\n",
       "              -0.12244217, -0.1424665 , -0.035817  , -0.28059295,\n",
       "               0.4060092 , -0.24126501,  0.07064393,  0.24595548,\n",
       "               0.21735178, -0.20369458, -0.2550666 , -0.09907824,\n",
       "              -0.16886546, -0.156735  ,  0.22088106, -0.2554009 ,\n",
       "               0.22527976,  0.01693153, -0.13935685,  0.05901127,\n",
       "              -0.06504919, -0.01195625,  0.21463275, -0.3685163 ,\n",
       "              -0.3184388 ,  0.07725074, -0.15126444,  0.1248764 ,\n",
       "              -0.24204478, -0.23994994, -0.15684944,  0.11890649,\n",
       "              -0.24165146,  0.22362165, -0.1281218 , -0.25187027,\n",
       "              -0.432744  , -0.10779948,  0.44965369,  0.20622529,\n",
       "               0.3354444 , -0.08273225,  0.08370974, -0.01243094,\n",
       "               0.21244329,  0.0997375 , -0.02911203,  0.02758815,\n",
       "               0.03849116, -0.00375877, -0.09456719,  0.13348791,\n",
       "               0.151057  , -0.07747152, -0.33459055,  0.12894626,\n",
       "               0.14054832, -0.03309862, -0.27520385,  0.21278559,\n",
       "               0.05403799, -0.12580417,  0.20772724,  0.3368731 ,\n",
       "              -0.39993647, -0.04383377, -0.13966863,  0.21011631,\n",
       "               0.06366866,  0.17800322, -0.15550384, -0.03630481,\n",
       "              -0.07961879, -0.07511108,  0.05903248, -0.20566314,\n",
       "               0.28900912,  0.30845073,  0.14198934, -0.35425076,\n",
       "              -0.04037248,  0.28928077,  0.11982277,  0.02272012,\n",
       "              -0.08954353, -0.12531327, -0.01929968, -0.33411044,\n",
       "              -0.09123003,  0.11294997,  0.078385  , -0.05394091,\n",
       "               0.14658915,  0.1218291 ,  0.06165171, -0.21158133,\n",
       "              -0.1341736 , -0.0213023 ,  0.14684795, -0.21689402,\n",
       "              -0.07597058,  0.32661697,  0.26170292,  0.2193437 ,\n",
       "               0.33523405,  0.20762676, -0.12341539,  0.12083093,\n",
       "              -0.1643071 , -0.44498038,  0.03145083,  0.41662908,\n",
       "               0.16050947, -0.14206906, -0.4688087 ,  0.09122235,\n",
       "               0.34813824,  0.17531146,  0.03857527,  0.28798935,\n",
       "              -0.00433024, -0.27819458,  0.17539552, -0.02279656,\n",
       "              -0.44798052, -0.07991753, -0.2022331 , -0.18531224,\n",
       "              -0.01367931,  0.24246609,  0.48532346, -0.12623978,\n",
       "              -0.05218321,  0.0393114 , -0.06226489, -0.41129985,\n",
       "               0.22774012, -0.10747542, -0.29513937,  0.11239919,\n",
       "              -0.3562258 ,  0.00897099,  0.27722648, -0.03176131,\n",
       "              -0.2561873 , -0.38392535, -0.26136062, -0.05999115,\n",
       "               0.08067327, -0.19734864, -0.0089897 , -0.3945198 ,\n",
       "               0.14967284, -0.20786156, -0.20238589, -0.1841232 ,\n",
       "               0.33611405, -0.1743268 , -0.2666594 ,  0.14201091]],            dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Dataset, using wikipedia dataset for training. The retrieval model predicts extracted text from a wikipedia paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset wikitext (/Users/maxgubin/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "\n",
    "def extract_random_sentence(example):\n",
    "    \"\"\"Sample one sentence from a paragraph.\"\"\"\n",
    "    sentences = example['text'].split('.')\n",
    "    sentences_len = len(sentences)\n",
    "    if (sentences_len < 2):\n",
    "        return {'paragraph': '', 'sample': ''}\n",
    "    sampled_id = python_random.randint(0, sentences_len-1)\n",
    "    paragraph = ' '.join(sentences[:sampled_id] + sentences[sampled_id+1:])\n",
    "    sampled_sentence = sentences[sampled_id]\n",
    "    if not sampled_sentence.strip() or not paragraph.strip():\n",
    "        return {'paragraph': '', 'sample': ''}\n",
    "\n",
    "    return {'paragraph': paragraph, 'sample': sampled_sentence}\n",
    "\n",
    "def filter_callback(example):\n",
    "    \"\"\"Filters out examples with an empty paragraph.\"\"\"\n",
    "    return len(example['paragraph']) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatastreamTokenize():\n",
    "    \"\"\"Creates a callback that performs tokenization and also batching\"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n",
    "    def TokenizerCallback(example):\n",
    "        build_tokenized_map = lambda prefix: {prefix+'_'+key: value for key, value in tokenizer(example['paragraph']).items()}\n",
    "        return build_tokenized_map('paragraph').update(build_tokenized_map('sample'))\n",
    "    return TokenizerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = extract_random_sentence({'text':'Hello World. Good bye'})\n",
    "\n",
    "DatastreamTokenize()(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/maxgubin/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-389dd8c8fdf40d13.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/maxgubin/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-336560af76215cb6.arrow\n",
      "  0%|          | 0/385 [00:00<?, ?ba/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Provided `function` which is applied to all elements of table returns a `dict` of types {[type(x) for x in processed_inputs.values()]}. When using `batched=True`, make sure provided `function` returns a `dict` of types like `{allowed_batch_return_types}`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cg/x9_ps0h51v74s2l1plwv1ffh0000gn/T/ipykernel_19273/3980703369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepared_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_random_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatastreamTokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m             return self._map_single(\n\u001b[0m\u001b[1;32m   2019\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m         }\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2387\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   2388\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   2390\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2279\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m                 \u001b[0mupdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2281\u001b[0;31m                 \u001b[0mvalidate_function_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Nothing to update, let's move on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LM/experiment/.venv/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mvalidate_function_output\u001b[0;34m(processed_inputs, indices)\u001b[0m\n\u001b[1;32m   2258\u001b[0m                 )\n\u001b[1;32m   2259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall_dict_values_are_lists\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2260\u001b[0;31m                     raise TypeError(\n\u001b[0m\u001b[1;32m   2261\u001b[0m                         \u001b[0;34m\"Provided `function` which is applied to all elements of table returns a `dict` of types {[type(x) for x in processed_inputs.values()]}. When using `batched=True`, make sure provided `function` returns a `dict` of types like `{allowed_batch_return_types}`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m                     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Provided `function` which is applied to all elements of table returns a `dict` of types {[type(x) for x in processed_inputs.values()]}. When using `batched=True`, make sure provided `function` returns a `dict` of types like `{allowed_batch_return_types}`."
     ]
    }
   ],
   "source": [
    "prepared_dataset = dataset.map(extract_random_sentence).filter(filter_callback).map(DatastreamTokenize(), batched=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12313, 3), (36718, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset.shape, dataset.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb946ab6d564da0bdba9ddd165544fac8a130888ddc3a3ba6dd5d5eb44c22d78"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
